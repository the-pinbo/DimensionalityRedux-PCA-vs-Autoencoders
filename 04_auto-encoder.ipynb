{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\inba2\\Desktop\\CSSP\\Assignment\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape => (60000, 28, 28)\n",
      "X_test.shape => (10000, 28, 28)\n",
      "Y_train.shape => (60000,)\n",
      "Y_test.shape => (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "print(f\"X_train.shape => {X_train.shape}\")\n",
    "print(f\"X_test.shape => {X_test.shape}\")\n",
    "print(f\"Y_train.shape => {Y_train.shape}\")\n",
    "print(f\"Y_test.shape => {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_shape, latent_dim, encoder_units, decoder_units, dropout_rate):\n",
    "    # Encoder\n",
    "    encoder_input = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Flatten()(encoder_input)\n",
    "    for units in encoder_units:\n",
    "        x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    encoded_output = tf.keras.layers.Dense(latent_dim, activation='relu')(x)\n",
    "    encoder = tf.keras.Model(inputs=encoder_input, outputs=encoded_output, name='encoder')\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = tf.keras.Input(shape=(latent_dim,))\n",
    "    x = decoder_input\n",
    "    for units in decoder_units:\n",
    "        x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(tf.math.reduce_prod(input_shape), activation='relu')(x)\n",
    "    decoded_output = tf.keras.layers.Reshape(input_shape)(x)\n",
    "    decoder = tf.keras.Model(inputs=decoder_input, outputs=decoded_output, name='decoder')\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder_input = tf.keras.Input(shape=input_shape)\n",
    "    encoded = encoder(autoencoder_input)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = tf.keras.Model(inputs=autoencoder_input, outputs=decoded, name='autoencoder')\n",
    "\n",
    "    return autoencoder, encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(original, reconstructed):\n",
    "    return compare_psnr(original, reconstructed, data_range=original.max() - original.min())\n",
    "\n",
    "def calculate_ssim(original, reconstructed):\n",
    "    return compare_ssim(original, reconstructed, multichannel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_early_stopping(model, X_train, epochs, batch_size, patience=5):\n",
    "    \"\"\"\n",
    "    Trains the given model on the provided data with early stopping.\n",
    "\n",
    "    Parameters:\n",
    "    model: A TensorFlow/Keras model.\n",
    "    X_train (np.array): Training data.\n",
    "    epochs (int): Number of epochs to train the model.\n",
    "    batch_size (int): Batch size for training.\n",
    "    patience (int): Number of epochs to wait for improvement before stopping.\n",
    "\n",
    "    Returns:\n",
    "    history: Training history object.\n",
    "    \"\"\"\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_split=0.2, callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model, X_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss During Training')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_shape = X_train.shape[1:]\n",
    "dropout_rate = 0.2\n",
    "output_shape = X_train.shape[1:]\n",
    "encoder_units = [512, 256, 128]\n",
    "decoder_units = [128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\inba2\\Desktop\\CSSP\\Assignment\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Latent dim => 2\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 2)                 566402    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_1 (InputLayer)       [(None, 28, 28)]          0        |\n",
      "|                                                               |\n",
      "| flatten (Flatten)          (None, 784)               0        |\n",
      "|                                                               |\n",
      "| dense (Dense)              (None, 512)               401920   |\n",
      "|                                                               |\n",
      "| dropout (Dropout)          (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_1 (Dense)            (None, 256)               131328   |\n",
      "|                                                               |\n",
      "| dropout_1 (Dropout)        (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_2 (Dense)            (None, 128)               32896    |\n",
      "|                                                               |\n",
      "| dropout_2 (Dropout)        (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_3 (Dense)            (None, 2)                 258      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " decoder (Functional)        (None, 28, 28)            567184    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_2 (InputLayer)       [(None, 2)]               0        |\n",
      "|                                                               |\n",
      "| dense_4 (Dense)            (None, 128)               384      |\n",
      "|                                                               |\n",
      "| dropout_3 (Dropout)        (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_5 (Dense)            (None, 256)               33024    |\n",
      "|                                                               |\n",
      "| dropout_4 (Dropout)        (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_6 (Dense)            (None, 512)               131584   |\n",
      "|                                                               |\n",
      "| dropout_5 (Dropout)        (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_7 (Dense)            (None, 784)               402192   |\n",
      "|                                                               |\n",
      "| reshape (Reshape)          (None, 28, 28)            0        |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 1133586 (4.32 MB)\n",
      "Trainable params: 1133586 (4.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Latent dim => 8\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 8)                 567176    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_4 (InputLayer)       [(None, 28, 28)]          0        |\n",
      "|                                                               |\n",
      "| flatten_1 (Flatten)        (None, 784)               0        |\n",
      "|                                                               |\n",
      "| dense_8 (Dense)            (None, 512)               401920   |\n",
      "|                                                               |\n",
      "| dropout_6 (Dropout)        (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_9 (Dense)            (None, 256)               131328   |\n",
      "|                                                               |\n",
      "| dropout_7 (Dropout)        (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_10 (Dense)           (None, 128)               32896    |\n",
      "|                                                               |\n",
      "| dropout_8 (Dropout)        (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_11 (Dense)           (None, 8)                 1032     |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " decoder (Functional)        (None, 28, 28)            567952    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_5 (InputLayer)       [(None, 8)]               0        |\n",
      "|                                                               |\n",
      "| dense_12 (Dense)           (None, 128)               1152     |\n",
      "|                                                               |\n",
      "| dropout_9 (Dropout)        (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_13 (Dense)           (None, 256)               33024    |\n",
      "|                                                               |\n",
      "| dropout_10 (Dropout)       (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_14 (Dense)           (None, 512)               131584   |\n",
      "|                                                               |\n",
      "| dropout_11 (Dropout)       (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_15 (Dense)           (None, 784)               402192   |\n",
      "|                                                               |\n",
      "| reshape_1 (Reshape)        (None, 28, 28)            0        |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 1135128 (4.33 MB)\n",
      "Trainable params: 1135128 (4.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Latent dim => 32\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 32)                570272    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_7 (InputLayer)       [(None, 28, 28)]          0        |\n",
      "|                                                               |\n",
      "| flatten_2 (Flatten)        (None, 784)               0        |\n",
      "|                                                               |\n",
      "| dense_16 (Dense)           (None, 512)               401920   |\n",
      "|                                                               |\n",
      "| dropout_12 (Dropout)       (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_17 (Dense)           (None, 256)               131328   |\n",
      "|                                                               |\n",
      "| dropout_13 (Dropout)       (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_18 (Dense)           (None, 128)               32896    |\n",
      "|                                                               |\n",
      "| dropout_14 (Dropout)       (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_19 (Dense)           (None, 32)                4128     |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " decoder (Functional)        (None, 28, 28)            571024    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_8 (InputLayer)       [(None, 32)]              0        |\n",
      "|                                                               |\n",
      "| dense_20 (Dense)           (None, 128)               4224     |\n",
      "|                                                               |\n",
      "| dropout_15 (Dropout)       (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_21 (Dense)           (None, 256)               33024    |\n",
      "|                                                               |\n",
      "| dropout_16 (Dropout)       (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_22 (Dense)           (None, 512)               131584   |\n",
      "|                                                               |\n",
      "| dropout_17 (Dropout)       (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_23 (Dense)           (None, 784)               402192   |\n",
      "|                                                               |\n",
      "| reshape_2 (Reshape)        (None, 28, 28)            0        |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 1141296 (4.35 MB)\n",
      "Trainable params: 1141296 (4.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Latent dim => 64\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 64)                574400    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_10 (InputLayer)      [(None, 28, 28)]          0        |\n",
      "|                                                               |\n",
      "| flatten_3 (Flatten)        (None, 784)               0        |\n",
      "|                                                               |\n",
      "| dense_24 (Dense)           (None, 512)               401920   |\n",
      "|                                                               |\n",
      "| dropout_18 (Dropout)       (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_25 (Dense)           (None, 256)               131328   |\n",
      "|                                                               |\n",
      "| dropout_19 (Dropout)       (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_26 (Dense)           (None, 128)               32896    |\n",
      "|                                                               |\n",
      "| dropout_20 (Dropout)       (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_27 (Dense)           (None, 64)                8256     |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " decoder (Functional)        (None, 28, 28)            575120    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_11 (InputLayer)      [(None, 64)]              0        |\n",
      "|                                                               |\n",
      "| dense_28 (Dense)           (None, 128)               8320     |\n",
      "|                                                               |\n",
      "| dropout_21 (Dropout)       (None, 128)               0        |\n",
      "|                                                               |\n",
      "| dense_29 (Dense)           (None, 256)               33024    |\n",
      "|                                                               |\n",
      "| dropout_22 (Dropout)       (None, 256)               0        |\n",
      "|                                                               |\n",
      "| dense_30 (Dense)           (None, 512)               131584   |\n",
      "|                                                               |\n",
      "| dropout_23 (Dropout)       (None, 512)               0        |\n",
      "|                                                               |\n",
      "| dense_31 (Dense)           (None, 784)               402192   |\n",
      "|                                                               |\n",
      "| reshape_3 (Reshape)        (None, 28, 28)            0        |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 1149520 (4.39 MB)\n",
      "Trainable params: 1149520 (4.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "latent_dims = [2, 8, 32, 64]\n",
    "autoencoders = dict()\n",
    "\n",
    "for latent_dim in latent_dims:\n",
    "    # Build and compile the autoencoder\n",
    "    autoencoder, _, _ = build_autoencoder(input_shape, latent_dim, encoder_units, decoder_units, dropout_rate)\n",
    "    autoencoder.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "    autoencoders[latent_dim] = autoencoder\n",
    "    print(f\"Latent dim => {latent_dim}\")\n",
    "    print(autoencoder.summary(expand_nested=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstructions(original, reconstructed, n_images, title):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n_images):\n",
    "        # Display original image\n",
    "        ax = plt.subplot(2, n_images, i + 1)\n",
    "        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # Display reconstructed image\n",
    "        ax = plt.subplot(2, n_images, i + 1 + n_images)\n",
    "        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model, X_train, epochs, batch_size, patience=5):\n",
    "    \"\"\"\n",
    "    Trains the given model on the provided data with early stopping.\n",
    "\n",
    "    Parameters:\n",
    "    model: A TensorFlow/Keras model.\n",
    "    X_train (np.array): Training data.\n",
    "    epochs (int): Number of epochs to train the model.\n",
    "    batch_size (int): Batch size for training.\n",
    "    patience (int): Number of epochs to wait for improvement before stopping.\n",
    "\n",
    "    Returns:\n",
    "    history: Training history object.\n",
    "    \"\"\"\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_split=0.2, callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images = dict()\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "\n",
    "for latent_dim, autoencoder in autoencoders.items():\n",
    "    print(f\"Latent dim => {latent_dim}\")\n",
    "    # Train the model\n",
    "    history = train_model(autoencoder, X_train, epochs=50, batch_size=128)\n",
    "    # Predict using the model\n",
    "    predictions = predict_model(autoencoder, X_test)\n",
    "    reconstructed_images[latent_dim] = predictions\n",
    "    # Plot the training history\n",
    "    plot_training_history(history)\n",
    "\n",
    "    # Calculate PSNR and SSIM\n",
    "    psnr = calculate_psnr(X_test, predictions)\n",
    "    ssim = calculate_ssim(X_test, predictions)\n",
    "    psnr_values.append(psnr)\n",
    "    ssim_values.append(ssim)\n",
    "\n",
    "    # Visualization\n",
    "    title = f\"Autoencoder with Latent Dimension {latent_dim} - PSNR: {psnr:.2f}, SSIM: {ssim:.2f}\"\n",
    "    visualize_reconstructions(X_test, predictions, n_images_to_display, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an image for comparison\n",
    "index_of_image_to_compare = 0  # You can change this index\n",
    "selected_image = X_test[index_of_image_to_compare]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, latent_dim in enumerate(latent_dims):\n",
    "    reconstructed_image = reconstructed_images[latent_dim][index_of_image_to_compare]\n",
    "    \n",
    "    # Display reconstructed image\n",
    "    ax = plt.subplot(2, len(latent_dims), i + 1)\n",
    "    plt.imshow(reconstructed_image.reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Latent Dim: {latent_dim}\\nPSNR: {psnr_values[i]:.2f}\\nSSIM: {ssim_values[i]:.2f}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Display the original image for comparison\n",
    "ax = plt.subplot(2, len(latent_dims), len(latent_dims) + 1)\n",
    "plt.imshow(selected_image.reshape(28, 28), cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PSNR and SSIM graphs\n",
    "fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# PSNR Plot\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Latent Dimension')\n",
    "ax1.set_ylabel('PSNR (dB)', color=color)\n",
    "ax1.plot(latent_dims, psnr_values, 'o-', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# SSIM Plot on the same x-axis\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('SSIM', color=color)\n",
    "ax2.plot(latent_dims, ssim_values, 's-', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Layout and grid\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.grid(True)\n",
    "plt.title('PSNR and SSIM Values for Different Latent Dimensions')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
